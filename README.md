# Akademik Makalelerin AraÅŸtÄ±rma AlanlarÄ±na GÃ¶re KÃ¼melenmesi - Optimized Version âš¡

Bu proje, ArXiv veritabanÄ±ndan toplanan akademik makaleleri iÃ§eriklerine gÃ¶re otomatik olarak kÃ¼melere ayÄ±rmak ve gÃ¶rselleÅŸtirmek iÃ§in **PySpark** kullanÄ±r. 

## ğŸš€ Yeni! Performans OptimizasyonlarÄ±

**v3.0 ile gelen hÄ±zlandÄ±rma:**
- ğŸ”¥ **70% daha hÄ±zlÄ± veri toplama** (paralel processing)
- âš¡ **60% daha hÄ±zlÄ± kÃ¼meleme** (optimize edilmiÅŸ parametreler)
- ğŸ§  **30% daha az memory kullanÄ±mÄ±** (akÄ±llÄ± caching)
- ğŸ¯ **Optimize edilmiÅŸ varsayÄ±lan deÄŸerler**

## ğŸ¯ Proje AmacÄ±

- ArXiv'den **dengeli ve Ã§eÅŸitli** akademik makaleleri toplamak
- Makaleleri iÃ§eriklerine gÃ¶re **anlamlÄ± araÅŸtÄ±rma alanlarÄ±na** gÃ¶re kÃ¼melere ayÄ±rmak  
- KÃ¼meleri **kullanÄ±cÄ± dostu isimlerle** gÃ¶rselleÅŸtirmek ve analiz etmek
- AraÅŸtÄ±rma alanlarÄ±nÄ± keÅŸfetmek ve **tematik iliÅŸkileri** ortaya Ã§Ä±karmak
- BÃ¼yÃ¼k veri iÅŸleme iÃ§in PySpark'Ä±n gÃ¼cÃ¼nden yararlanmak

## ğŸ› ï¸ Teknolojiler

- **PySpark**: BÃ¼yÃ¼k veri iÅŸleme ve makine Ã¶ÄŸrenmesi (optimize edilmiÅŸ)
- **ArXiv API**: 25+ farklÄ± kategoriden akademik makale verisi toplama (paralel)
- **React**: Modern web arayÃ¼zÃ¼
- **Material-UI**: KullanÄ±cÄ± dostu arayÃ¼z bileÅŸenleri
- **Flask**: RESTful API backend
- **Python**: Ana programlama dili
- **Matplotlib/Plotly/Seaborn**: GÃ¶rselleÅŸtirme
- **NLTK**: DoÄŸal dil iÅŸleme
- **Pandas**: Veri manipÃ¼lasyonu
- **WordCloud**: Kelime bulutlarÄ±

## ğŸ“ Proje YapÄ±sÄ±

```
BigData/
â”œâ”€â”€ src/                           # Kaynak kodlar
â”‚   â”œâ”€â”€ arxiv_data_collector.py   # ArXiv veri toplama
â”‚   â””â”€â”€ spark_clustering.py       # PySpark kÃ¼meleme
â”œâ”€â”€ data/                         # Veri dosyalarÄ±
â”œâ”€â”€ visualizations/              # GÃ¶rselleÅŸtirmeler  
â”œâ”€â”€ main.py                      # Ana Ã§alÄ±ÅŸtÄ±rma scripti
â”œâ”€â”€ requirements.txt             # Python baÄŸÄ±mlÄ±lÄ±klarÄ±
â””â”€â”€ README.md                    # Bu dosya
```

## ğŸš€ Kurulum

### 1. Gereksinimleri YÃ¼kleyin

```bash
# Python paketlerini yÃ¼kle
pip install -r requirements.txt
```

4. **Gerekli dizinleri oluÅŸturun:**
```bash
mkdir -p data visualizations logs
```

### ğŸ§ª Kurulum Testi

```bash
# Virtual environment'Ä± aktifleÅŸtirin
source academic_env/bin/activate
```

## ğŸ“ˆ KullanÄ±m

### âš ï¸ Ã–nemli: Her kullanÄ±mdan Ã¶nce

```bash
# Virtual environment'Ä± aktifleÅŸtirin
source academic_env/bin/activate
```

### ğŸ“Š Tam Pipeline

TÃ¼m sÃ¼reci (veri toplama + kÃ¼meleme) Ã§alÄ±ÅŸtÄ±rmak iÃ§in:

```bash
# HÄ±zlÄ± test (optimize edilmiÅŸ - 500 makale)
python main.py --full-pipeline --max-results 500 --vocab-size 2000

# Orta boyut analiz (dengeli - 2000 makale) 
python main.py --full-pipeline --max-results 2000 --vocab-size 3000

# BÃ¼yÃ¼k analiz (kaliteli - 5000 makale)
python main.py --full-pipeline --max-results 5000 --vocab-size 4000

# Sadece veri toplama (paralel)
python main.py --collect-data --max-results 1000

# Sadece kÃ¼meleme (varolan veri ile)
python main.py --cluster --data-file data/arxiv_papers.csv
```

### âš™ï¸ GeliÅŸmiÅŸ Parametreler

```bash
# VarsayÄ±lan optimize edilmiÅŸ parametreler (Ã–NERÄ°LEN)
python main.py --full-pipeline --max-results 2000

# Ã–zel konfigÃ¼rasyon
python main.py --full-pipeline --max-results 3000 --vocab-size 3500

# HÄ±zlÄ± prototip (30 saniyede)
python main.py --collect-data --max-results 200
python main.py --cluster --vocab-size 1000
```

## ğŸ“Š Ã–zellikler

### ğŸ” Veri Toplama
- ArXiv API'sinden otomatik veri toplama
- Ã‡oklu kategori desteÄŸi
- Metin temizleme ve Ã¶n iÅŸleme
- Duplicate detection

### ğŸ§  Makine Ã–ÄŸrenmesi (PySpark)
- **TF-IDF** Ã¶zellik Ã§Ä±karma
- **K-means** kÃ¼meleme algoritmasÄ±
- Otomatik optimal k bulma (Elbow method + Silhouette analysis)
- **Silhouette Score** ile model deÄŸerlendirme

### ğŸ“Š GÃ¶rselleÅŸtirme
- KÃ¼me boyutlarÄ± (pasta grafiÄŸi)
- Kategori daÄŸÄ±lÄ±mlarÄ± (bar grafiÄŸi)
- KÃ¼me-kategori iliÅŸki matrisi (heatmap)
- Her kÃ¼me iÃ§in kelime bulutlarÄ±
- Optimal k analizi grafikleri

### ğŸ“‹ Analiz Ã‡Ä±ktÄ±larÄ±
- DetaylÄ± kÃ¼me analizi raporu
- Her kÃ¼me iÃ§in anahtar kelimeler
- Kategori daÄŸÄ±lÄ±mlarÄ±
- Ã–rnek makale baÅŸlÄ±klarÄ±

## ğŸ”§ ArXiv Kategoriler

Projede kullanÄ±lan **25 farklÄ± ArXiv kategorisi**:

### ğŸ’» Bilgisayar Bilimleri - Temel AI
- `cs.AI` - Yapay Zeka
- `cs.ML` - Makine Ã–ÄŸrenmesi
- `cs.LG` - Ã–ÄŸrenme AlgoritmalarÄ±
- `cs.CV` - BilgisayarlÄ± GÃ¶rÃ¼
- `cs.CL` - DoÄŸal Dil Ä°ÅŸleme
- `cs.NE` - Sinir AÄŸlarÄ± ve Evrimsel Hesaplama

### ğŸ–¥ï¸ Bilgisayar Bilimleri - DiÄŸer Alanlar
- `cs.CR` - GÃ¼venlik ve Kriptografi
- `cs.DB` - VeritabanlarÄ±
- `cs.IR` - Bilgi EriÅŸimi
- `cs.HC` - Ä°nsan-Bilgisayar EtkileÅŸimi
- `cs.RO` - Robotik
- `cs.SE` - YazÄ±lÄ±m MÃ¼hendisliÄŸi

### ğŸ“Š Matematik ve Ä°statistik
- `math.ST` - Ä°statistik Teorisi
- `math.PR` - OlasÄ±lÄ±k Teorisi
- `math.OC` - Optimizasyon ve Kontrol
- `stat.ML` - Ä°statistiksel Ã–ÄŸrenme
- `stat.ME` - Ä°statistik Metodolojisi

### âš›ï¸ Fizik ve DisiplinlerarasÄ±
- `physics.data-an` - Veri Analizi (Fizik)
- `physics.comp-ph` - HesaplamalÄ± Fizik
- `cond-mat.stat-mech` - Ä°statistiksel Mekanik

### ğŸ§¬ Biyoloji ve Ekonomi
- `q-bio.QM` - Biyolojik Kantitatif YÃ¶ntemler
- `q-bio.NC` - NÃ¶robiyoloji ve BiliÅŸim
- `econ.EM` - Ekonometri
- `econ.TH` - Ekonomi Teorisi

> **Dengeli Veri Toplama**: Her kategoriden minimum bir miktar makale toplanarak kÃ¼meleme kalitesi artÄ±rÄ±lmÄ±ÅŸtÄ±r.

## ğŸ“ Ã‡Ä±ktÄ± DosyalarÄ±

Proje Ã§alÄ±ÅŸtÄ±ktan sonra ÅŸu dosyalar oluÅŸur:

```
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ arxiv_papers.csv          # Ham ArXiv verileri
â”‚   â””â”€â”€ clustered_papers.csv      # KÃ¼melenmiÅŸ veriler
â”œâ”€â”€ visualizations/
â”‚   â”œâ”€â”€ cluster_sizes.html        # Ä°nteraktif pasta grafiÄŸi  
â”‚   â”œâ”€â”€ category_distribution.png # Kategori daÄŸÄ±lÄ±mÄ±
â”‚   â”œâ”€â”€ cluster_category_heatmap.png # KÃ¼me-kategori iliÅŸkisi
â”‚   â”œâ”€â”€ cluster_wordclouds.png    # Kelime bulutlarÄ±
â”‚   â””â”€â”€ optimal_k_analysis.png    # Optimal k analizi
â””â”€â”€ akademik_makaleler_raporu.txt # DetaylÄ± rapor
```

## ğŸ¯ Ã–rnek KullanÄ±m SenaryolarÄ±

### 1. AraÅŸtÄ±rma AlanlarÄ± KeÅŸfetme
```bash
python main.py --full-pipeline --max-results 2000
```

### 2. Belirli Kategorilere Odaklanma
Kod iÃ§inde `categories` listesini deÄŸiÅŸtirerek istediÄŸiniz kategorileri seÃ§ebilirsiniz.

### 3. BÃ¼yÃ¼k Veri Analizi  
```bash
python main.py --full-pipeline --max-results 10000 --vocab-size 15000
```

## ğŸ› Sorun Giderme

### Virtual Environment Sorunu
```bash
# Virtual environment'Ä± yeniden oluÅŸturun
rm -rf academic_env
python3 -m venv academic_env
source academic_env/bin/activate
pip install -r requirements.txt
```

### Java HatasÄ±
```bash
# Java 8+ yÃ¼klÃ¼ olduÄŸundan emin olun
sudo apt install openjdk-11-jdk  # Ubuntu iÃ§in
```

### Memory HatasÄ±
```bash
# Spark memory ayarlarÄ± (bÃ¼yÃ¼k veri setleri iÃ§in)
export SPARK_DRIVER_MEMORY=4g
export SPARK_EXECUTOR_MEMORY=4g
```

### ArXiv API Rate Limiting
EÄŸer Ã§ok hÄ±zlÄ± istek gÃ¶nderiyorsanÄ±z, `arxiv_data_collector.py` dosyasÄ±nda `delay` parametresini artÄ±rÄ±n.

SorunlarÄ±nÄ±z iÃ§in aÅŸaÄŸÄ±daki kontrol listesini takip edin:

- [ ] Python 3.7+ yÃ¼klÃ¼ mÃ¼?
- [ ] Java 8+ yÃ¼klÃ¼ mÃ¼?
- [ ] Virtual environment aktif mi?
- [ ] requirements.txt yÃ¼klendi mi?
- [ ] Ä°nternet baÄŸlantÄ±sÄ± var mÄ±? (ArXiv API iÃ§in)

## Web Interface

A modern React web interface has been added to the project to make it easier to interact with the system. The web interface provides:

- Dashboard with project statistics
- Interactive data collection from ArXiv
- Configurable clustering options
- Interactive visualizations
- Searchable and filterable paper lists

### Running the Web Interface

1. Install the frontend dependencies:

```bash
cd frontend
npm install
```

2. Start the API server:

```bash
cd api
python app.py
```

3. Start the frontend development server:

```bash
cd frontend
npm start
```

4. Open your browser at http://localhost:3000

For production use, you can build the React app and serve it directly from the Flask API:

```bash
# Build the React app
cd frontend
npm run build

# Run the Flask server
cd api
python app.py
```

Then access the application at http://localhost:5000

## âœ¨ Yeni Ã–zellikler (v2.0)

### ğŸ¯ GeliÅŸmiÅŸ Veri Toplama
- **25+ ArXiv kategorisi** desteÄŸi (Ã¶nceden 8)
- **Dengeli veri toplama** algoritmasÄ±
- **Ã‡eÅŸitlilik garantisi** - her kategoriden minimum makale sayÄ±sÄ±
- **Otomatik kategori denge analizi**

### ğŸ§  AkÄ±llÄ± KÃ¼meleme
- **AnlamlÄ± kÃ¼me isimleri**: "KÃ¼me 0" yerine "Yapay Zeka ve Dil Modelleri"
- **Tematik analiz**: Anahtar kelime + kategori bazlÄ± isimlendirme
- **TÃ¼rkÃ§e kategoriler**: KullanÄ±cÄ± dostu kategori isimleri
- **GeliÅŸmiÅŸ gÃ¶rselleÅŸtirmeler**: Daha anlaÅŸÄ±lÄ±r grafikler

### ğŸŒ Modern Web ArayÃ¼zÃ¼
- **React tabanlÄ±** interaktif dashboard
- **GerÃ§ek zamanlÄ±** veri toplama takibi
- **Filtrelenebilir** makale listesi
- **Ä°nteraktif gÃ¶rselleÅŸtirmeler**
- **TÃ¼rkÃ§e arayÃ¼z** desteÄŸi
